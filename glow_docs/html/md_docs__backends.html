<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Glow: Backends in Glow</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Glow
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Backends in Glow </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>There are two directories used by backends in Glow:</p>
<ol type="1">
<li><a href="https://github.com/pytorch/glow/tree/master/tools/ClassGen/Backends">tools/ClassGen/Backends/</a>: Each backend directory here contains new <a href="#backend-specific-nodes-and-instructions-transformations">backend-specific</a> Nodes and Instructions for the backends. If a backend provides its own backend-specific nodes/instructions, they should be included in <a href="https://github.com/pytorch/glow/blob/master/tools/ClassGen/NodeGen.cpp">NodeGen</a>/<a href="https://github.com/pytorch/glow/blob/master/tools/ClassGen/InstrGen.cpp">InstrGen</a>.</li>
<li><a href="https://github.com/pytorch/glow/tree/master/lib/Backends">lib/Backends/</a>: The implementation of the backend is contained here. This includes derived classes for <a href="#backend-abstract-class"><code>Backend</code></a> and <a href="#compiledfunction-abstract-class"><code>CompiledFunction</code></a>. Each backend needs to be registered through its own registration factory in order to be discovered by Glow, see <a href="https://github.com/pytorch/glow/blob/master/lib/Backends/CPU/CPUFactory.cpp">CPUBackend for example</a>. And all factories must be linked to the Backends library, see <a href="https://github.com/pytorch/glow/blob/master/lib/Backends/CMakeLists.txt">here</a>.</li>
</ol>
<h3><code>Backend</code> Abstract Class</h3>
<p>All backends in Glow derive from the <a href="https://github.com/pytorch/glow/blob/master/include/glow/Backends/Backend.h">abstract base class <code>Backend</code></a>. There are two pure virtual functions all backends must implement:</p>
<ul>
<li><code>virtual std::unique_ptr&lt;CompiledFunction&gt; compile(Function *F) const;</code><ul>
<li>This function takes a <code>Function *F</code> to compile with default <a href="#backendoptions-helper-struct"><code>BackendOptions</code></a>. It should return a unique pointer to the <a href="#compiledfunction-abstract-class"><code>CompiledFunction</code></a> of <code>F</code>. If the backend uses Glow low-level IR, it can call <code>generateAndOptimizeIR()</code> to generate an optimized <code>IRFunction</code>.</li>
</ul>
</li>
<li><code>virtual std::unique_ptr&lt;CompiledFunction&gt; compile(Function *F, BackendOptions &amp;opts) const;</code><ul>
<li>This function takes a <code>Function *F</code> and the provided <a href="#backendoptions-helper-struct"><code>BackendOptions</code></a>. It should return a unique pointer to the <a href="#compiledfunction-abstract-class"><code>CompiledFunction</code></a> of <code>F</code>. If the backend uses Glow low-level IR, it can call <code>generateAndOptimizeIR()</code> to generate an optimized <code>IRFunction</code>.</li>
</ul>
</li>
<li><code>virtual std::vector&lt;std::unique_ptr&lt;CompiledFunction&gt;&gt; compileFunctions(llvm::ArrayRef&lt;Function *&gt; functions, BackendOptions &amp;opts) const;</code><ul>
<li>This function takes an <code>ArrayRef</code> of <code>Function *</code>s and compiles them using the same <code>BackendOptions</code> object for all functions. This allows the compiler to reason over things like shared constants between functions.</li>
</ul>
</li>
<li><code>virtual bool isOpSupported(const NodeInfo &amp;NI) const;</code><ul>
<li>Returns whether the backend can execute a node with given NodeInfo <code>NI</code>, containing the node kind and input and output types. For example, a backend may not support a specific bit-width quantization kind (e.g. <code>Int16QTy</code>) at all, or may only support it for certain operations (e.g. <code>ConvolutionNodeKind</code>). Any <code>(opKind, inputTypes, outputTypes)</code> passed in that returns true must be supported by the backed during <code>compile()</code> and <code>execute()</code>.</li>
</ul>
</li>
</ul>
<p>Additionally, there are virtual functions that backends can override:</p>
<ul>
<li><code>virtual bool transformPostLowering(Function *F, CompilationContext &amp;cctx) const;</code><ul>
<li>Allow the backend to transform the <code>Function *F</code> after <a href="https://github.com/pytorch/glow/blob/master/docs/IR.md#node-lowering">node lowering</a> occurs, given the <code>CompilationContext</code>. For example, the CPU backend prefers to transform MaxNodes, which take a SplatNode as an input, into a https://github.com/pytorch/glow/blob/master/docs/NewBackendSpecificNode.md "backend-specific" CPUMaxSplatNode, which takes a scalar value as a member input instead of a SplatNode. This should be done after node lowering, as ReluNodes are lowered into MaxNodes. See <a href="#backend-specific-nodes-and-instructions-transformations">below</a> for more information.</li>
</ul>
</li>
<li><code>virtual bool verify(const Function &amp;F) const;</code><ul>
<li>Verifies that <code>Function &amp;F</code> conforms to the backend-dependent graph constraints.</li>
</ul>
</li>
<li><code>virtual bool verify(const IRFunction &amp;IR) const;</code><ul>
<li>Verifies that <code>IRFunction &amp;IR</code> conforms to the backend-specific constraints.</li>
</ul>
</li>
<li><code>virtual bool shouldLower(const Node *N) const;</code><ul>
<li>Allow the backend to prevent lowering for some <code>Node *N</code>. For example, if a backend wants to fuse a <code>ReluNode</code> into a <code>ConvNode</code> to create some backend-specific node <code>ConvReluNode</code>, then it may prevent lowering for <code>ReluNode</code>. Then during <code>transformPostLowering()</code> it can look for patterns of <code>ConvNode</code> followed by <code>ReluNode</code> to swap out for <code>ConvReluNode</code>. Another example is if a backend supports executing a FullyConnected operator, it would want to prevent lowering for it and provide a backend-specific Instruction for the FullyConnectedNode to be <a href="https://github.com/pytorch/glow/blob/master/docs/IR.md#low-level-ir">IRGen'd</a> into. Note that IRGen for a Node can be specified via the https://github.com/pytorch/glow/blob/master/docs/ClassGen.md "ClassGen" <code>autoIRGen("NodeName")</code> call. See <a href="#backend-specific-nodes-and-instructions-transformations">below</a> for more information. Returns true if <code>N</code> should be lowered.</li>
</ul>
</li>
<li><code>virtual bool shouldShareBuffers() const;</code><ul>
<li>Allow the backend to disable the buffer sharing optimization. This may be preferred by backends which would like to do their own memory optimizations. Returns true by default.</li>
</ul>
</li>
<li><code>virtual void save(Function *F, llvm::StringRef outputDir, llvm::StringRef bundleName, llvm::StringRef mainEntryName) const;</code><ul>
<li>Save a https://github.com/pytorch/glow/blob/master/docs/AOT.md "standalone executable
    bundle", where the provided <code>Function *F</code> is compiled and then saved to <code>outputDir</code> with bundle name <code>bundleName</code> and main entry name <code>mainEntryName</code>.</li>
</ul>
</li>
<li><code>virtual bool generateInst(Node *N, IRGenVisitor &amp;irgen) const;</code><ul>
<li>Allow the backend to custom lower from Node to Instruction IR. Returns true if lowering is performed, false otherwise.</li>
</ul>
</li>
<li><code>virtual FunctionPassPipeline getOptimizationPipeline() const;</code><ul>
<li>Allows the backend to customize the graph optimizations that are performed when compiling a Function. Backend returns the "DefaultGraphOptimizationPassPipeline", which contains nearly all of the optimizations discussed <a href="Optimizations.md#set-of-supported-graph-optimizations">here</a>. More information on how to configure this pipeline can be found <a href="Optimizations.md#configuring-a-graph-optimization-pipeline">here</a>.</li>
</ul>
</li>
</ul>
<h3><code>CompiledFunction</code> Abstract Class</h3>
<p><code>CompiledFunction</code> is an abstract class that represents the result of compilation of a <code>Function</code>. Backends must implement their own derived class from <code>CompiledFunction</code>, which must be returned as a result of <code>Backend::compile()</code> or <code>Backend::compileWithoutConstants()</code> . <code>CompiledFunction</code> contains a pure virtual function that must be implemented: <code>virtual void execute();</code>. This function is responsible for copying inputs to the device from all input <a href="https://github.com/pytorch/glow/blob/master/docs/IR.md#placeholders">Placeholders</a>, executing the function, and copying outputs back from the device to output Placeholders. The <code>CompiledFunction</code> contains a <a href="#runtimebundle-helper-class">RuntimeBundle</a> which contains the symbol information and mappings of inputs and outputs. Thus after the function returns, all Placeholders for the outputs of the function should have had their backing tensor updated. An optional method: <code>virtual void freeCompilationResources()</code> can be implemented to allow freeing resources that are no longer needed after the function has been loaded on a device.</p>
<h3><code>RuntimeBundle</code> Helper Class</h3>
<p><code>RuntimeBundle</code> is a helper class that contains the symbol information and collection of constants needed at runtime. This allows a function to be compiled without being linked to a context, and allows the <code>Function</code> to be freed after compilation. The symbol information is stored in a table where the key is the symbol name and the payload contains symbol information including, size, offset, type, and whether it is an input or output of the function. <code>RuntimeBundle</code> also contains a pointer that may point to a block of memory that contains the constants for the <code>CompiledFunction</code> if that <code>Backend</code> uses it.</p>
<h3><code>BackendOptions</code> Helper Struct</h3>
<p><code>BackendOptions</code> is a helper struct that contains the options relevant to the backend for compilation. The options include:</p><ul>
<li><code>bool collectConstants</code> - Whether constants should be collected and stored in the <code>CompiledFunction</code>'s <a href="#runtimebundle-helper-class">RuntimeBundle</a>. Default: True</li>
<li><code>bool autoInstrument</code> - Whether <code>TraceEvents</code> should be inserted for profiling. Default: False</li>
</ul>
<h2>Backend-Specific Nodes and Instructions Transformations</h2>
<p>Different backends may prefer to transform or optimize the graph differently for their own specialized architecture. For example, Glow lowers ReLU down to a Max node, taking as inputs the original tensor and a "Splat" tensor of matching dimensions, filled with all <code>0</code>s. Glow's CPU JIT backend prefers to replace this pattern &ndash; a Max with a Splat input and another non-Splat input &ndash; with a single "CPUMaxSplat" operation that takes a scalar Splat value as input in place of an entire Splat tensor.</p>
<h3>Backend-Specific Transformation</h3>
<p>Backends have the opportunity to perform their own analysis and transformations after lowering. This is exposed via the <code>transformPostLowering()</code> hook, during which a backend can transform the graph however it desires. For example, the backend could use <code>transformPostLowering()</code> to search the graph looking for the above <code>CPUMaxSplat</code> pattern.</p>
<h4>Backend-Specific Nodes and Instructions</h4>
<p>A backend may create its own custom Nodes and Instructions which it can insert into the IR. This is done via ClassGen and implicitly included in <code>tools/ClassGen/NodeGen.cpp</code> and <code>tools/ClassGen/InstrGen.cpp</code>. These new nodes and instructions should be defined inside the backend sub-directory, in files <code>lib/Backends/&lt;BackendName&gt;/ClassGen/&lt;BackendName&gt;SpecificNodes.h</code> and <code>lib/Backends/&lt;BackendName&gt;/ClassGen/&lt;BackendName&gt;SpecificInstrs.h</code>:</p>
<p>For example, the CPU Backend defines <code>CPUMaxSplat</code> in <code><a class="el" href="_c_p_u_specific_nodes_8h_source.html">lib/Backends/CPU/ClassGen/CPUSpecificNodes.h</a></code>:</p>
<div class="fragment"><div class="line">BB.newBackendSpecificNode(<span class="stringliteral">&quot;CPUMaxSplat&quot;</span>)</div><div class="line">    .addInput(<span class="stringliteral">&quot;Input&quot;</span>)</div><div class="line">    .addResult(<span class="stringliteral">&quot;Input.getType()&quot;</span>)</div><div class="line">    .addMember(MemberType::Float, <span class="stringliteral">&quot;SplatValue&quot;</span>)</div><div class="line">    .setDocstring(<span class="stringliteral">&quot;A Max node with one splat input; CPU specific.&quot;</span>);</div></div><!-- fragment --><p>During <code>transformPostLowering()</code>, this <code>CPUMaxSplat</code> node replaces the aforementioned pattern. However, there must be a corresponding instruction for this Node to be lowered to during the IRGen phase. Thus, we need a corresponding backend-specific CPUMaxSplat instruction, defined in <code><a class="el" href="_c_p_u_specific_instrs_8h_source.html">lib/Backends/CPU/ClassGen/CPUSpecificInstrs.h</a></code>:</p>
<div class="fragment"><div class="line">BB.newBackendSpecificInstr(&quot;CPUMaxSplat&quot;)</div><div class="line">    .addOperand(&quot;Dest&quot;, OperandKind::Out)</div><div class="line">    .addOperand(&quot;Src&quot;, OperandKind::In)</div><div class="line">    .addMember(MemberType::Float, &quot;SplatValue&quot;)</div><div class="line">    .inplaceOperand({&quot;Dest&quot;, &quot;Src&quot;})</div><div class="line">    .dataParallel()</div><div class="line">    .autoIRGen();</div></div><!-- fragment --><p>These instructions will appear in the instruction stream sent to the CPU backend JIT; its <a href="JIT.md#usage-of-the-standard-library">standard library</a> has a kernel for executing this <code>CPUMaxSplat</code> instruction. You can see such instructions in the <a href="Example.md#lowering-to-ir">LeNet MNIST example</a>.</p>
<p>Note that backend-specific nodes and instructions can be treated just as any other node or instruction defined in <code>tools/ClassGen/NodeGen.cpp</code> or <code>tools/ClassGen/InstrGen.cpp</code>. For example, the <code>CPUMaxSplat</code> instruction definition includes the <code>dataParallel()</code> property, allowing for data parallel optimizations to take place.</p>
<p>The <code><a class="el" href="_c_p_u_specific_nodes_8h_source.html">lib/Backends/CPU/ClassGen/CPUSpecificNodes.h</a></code> and <code><a class="el" href="_c_p_u_specific_instrs_8h_source.html">lib/Backends/CPU/ClassGen/CPUSpecificInstrs.h</a></code> files are implicitly included in <code>tools/ClassGen/NodeGen.cpp</code> and <code>tools/ClassGen/InstrGen.cpp</code>, respectively.</p>
<h4>Backend Parameterized Tests</h4>
<p>Glow provides several test suites that are parameterized by backend. An example of such a suite is <code>tests/unittests/OperatorTest.cpp</code>, which defines small tests of Glow operators. These tests can be executed against any backend to check compliance.</p>
<p>These tests will only be run for a backend if a corresponding <code>lib/Backends/$BACKEND/tests</code> directory is found and contains a corresponding <code>${BACKEND}${TEST}.cpp</code> file containing a blacklist definition, e.g.: </p><div class="fragment"><div class="line">std::set&lt;std::string&gt; glow::backendTestBlacklist = {};</div></div><!-- fragment --><p>This blacklist can be used to exclude any unsupported tests while a backend is a work-in-progress. See the Interpreter and CPU backends for examples of setting up and using these tests. To bootstrap a blacklist, we recommend using a simple shell script to check which tests already work: </p><div class="fragment"><div class="line">for test in $(tests/ExampleBackendOperatorTest --gtest_list_tests); do</div><div class="line">  if ! tests/ExampleBackendOperatorTest --gtest_filter=&quot;$test&quot; &gt;&amp; /dev/null; then</div><div class="line">    echo $test</div><div class="line">  fi</div><div class="line">done</div></div><!-- fragment --><h4>External backends</h4>
<p>External backends can be added to Glow without changing the Glow build infrastructure.</p>
<p>An external backend is provided as a single source directory. It can then be developped in a separate source management repository.</p>
<p>The external backend mechanism is for instance convenient for adding closed source backends to Glow.</p>
<p>The structure of external backends is defined https://github.com/pytorch/glow/blob/master/docs/ExternalBackend.md "here". </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
