<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Glow: Creating standalone executable bundles</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Glow
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Creating standalone executable bundles </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>This document provides a short description about producing ahead-of-time compiled executable bundles. The motivation for this work is to remove the cost of compile time by allowing the users of Glow to compile the package ahead of time.</p>
<h2>Overview</h2>
<p>A bundle is a self-contained compiled network model that can be used to execute the model in a standalone mode. After following the instructions in this document and the <a href="../examples/bundles/resnet50/CMakeLists.txt">CMakeLists.txt</a> in the example directory you will be able to compile convolutional neural networks into small executables. Example:</p>
<div class="fragment"><div class="line">$cmake -G ninja &lt;other cmake flags&gt; -DGLOW_WITH_BUNDLES=ON -DGLOW_WITH_CPU=ON</div><div class="line">...</div><div class="line"></div><div class="line">$ninja ResNet50Bundle</div><div class="line">...</div><div class="line"></div><div class="line">$./resnet50 cat.png</div><div class="line">Result: 285</div></div><!-- fragment --><h2>Producing a bundle</h2>
<p>It is possible to use the Glow library to produce bundles. On the CPU, the bundles are object files that can be linked with some executable. On other architectures, the bundle may look completely different.</p>
<p>This document demonstrates how to produce a bundle for the host CPU using the 'image-classifier' tool. We use the flag <code>-emit-bundle</code> to specify the output directory.</p>
<div class="fragment"><div class="line">$image-classifier image.png -image-mode=0to1 -m=resnet50 -model-input-name=gpu_0/data -backend=CPU -emit-bundle build/</div></div><!-- fragment --><p>The command above would compile the neural network model described by the files <code>init_net.pb</code> and <code>predict_net.pb</code> located in the <code>network_model_directory_name</code> directory and generate a bundle consisting of two files in the directory <code>output_directory_name</code>, <code>&lt;network_name&gt;.o</code> and <code>&lt;network_name&gt;.weights</code> where <code>&lt;network_name&gt;</code> is by default equals to the last directory in the model path, i.e., <code>resnet50</code> in that case, and can be changed using <code>-network-name=&lt;network_name&gt;</code>. <code>predict_net.pb</code> describes the network model using the protobuf format for the ONNX or the <a class="el" href="namespacecaffe2.html">caffe2</a> representation. <code>init_net.pb</code> contains the weights that are used by the network using the protobuf format as well.</p>
<p>The first generated file is named <code>&lt;network_name&gt;.o</code> and contains the compiled code of the network model. By default, this is a non-relocatable object file that can be linked with other files in your project. It is possible to control the relocation model with the command line option <code>-relocation-model=&lt;mode&gt;</code>.</p>
<p>This option supports two modes:</p><ul>
<li><code>static</code>: (Default) Produce non-relocatable code.</li>
<li><code>pic</code>: Produce position independent code.</li>
</ul>
<p>The second generated file is named <code>&lt;network_name&gt;.weights</code> and contains the weights required to run the compiled model.</p>
<p>Another tool is the <code>model-compiler</code> which is used to compile a model into a bundle. This tool is more generic (is not tied just to image classification applications) and can compile models with any number of inputs. There is a difference when using this tool with ONNX or Caffe2 models:</p><ul>
<li>when using ONNX models the tool can infer automatically the inputs of the model since the description of the input tensors is part of the model. We can use this tool simply as: <div class="fragment"><div class="line">$model-compiler -model=&lt;onnx-model-path&gt; -backend=CPU -emit-bundle=&lt;bundle-dir&gt;</div></div><!-- fragment --></li>
<li>when using Caffe2 models the user must provide explicitly the description of the input tensors (which is not part of the model) using the <code>-model-input</code> option: <div class="fragment"><div class="line">$model-compiler -model=&lt;caffe2-model-path&gt; -backend=CPU -emit-bundle=&lt;bundle-dir&gt; \</div><div class="line">    -model-input=&lt;inputName1&gt;,&lt;inputType1&gt;,&lt;inputShape1&gt; \</div><div class="line">    -model-input=&lt;inputName2&gt;,&lt;inputType2&gt;,&lt;inputShape2&gt; \</div><div class="line">    ...</div></div><!-- fragment --> For quantized types the format of the <code>-model-input</code> is slightly different since the scale and offset parameters should also be provided: <div class="fragment"><div class="line">-model-input=&lt;name&gt;,&lt;type&gt;,&lt;scale&gt;,&lt;offset&gt;,&lt;shape&gt;</div></div><!-- fragment --> For example we can can provide one or more inputs with: <div class="fragment"><div class="line">-model-input=input_03_data,float,[1]</div><div class="line">-model-input=data_bias,int32,[1,32,32]</div><div class="line">-model-input=data,int8q,0.123,-13,[1,10]</div></div><!-- fragment --> For more information about the options of the model-compiler type: <div class="fragment"><div class="line">$model-compiler -help</div></div><!-- fragment --></li>
</ul>
<h2>APIs exposed by bundles</h2>
<p>This section describes the APIs that the CPU bundle exposes. Other targets may expose a completely different API.</p>
<p>Each bundle exposes two symbols named <code>&lt;network_name&gt;</code> and <code>&lt;network_name&gt;_config</code>, where, again, <code>&lt;network_name&gt;</code> is specified by the <code>-network-name</code> command line option. The <code>&lt;network_name&gt;</code> is the name of the auto-generated function that implements the network model. This symbol always has the following signature:</p>
<div class="fragment"><div class="line">{c++}</div><div class="line">extern &quot;C&quot; void network_name(uint8_t *constantWeightVars,</div><div class="line">                             uint8_t *mutableWeightVars,</div><div class="line">                             uint8_t *activations);</div></div><!-- fragment --><p> The parameters of this function are the base addresses of the memory areas for constant weights variables, mutable weights variables (i.e. inputs and outputs) and activations.</p>
<p>The <code>&lt;network_name&gt;_config</code> is a symbol that contains the configuration of the compiled network. The type of this symbol is always the following struct: </p><div class="fragment"><div class="line">{c++}</div><div class="line">struct BundleConfig {</div><div class="line">  // Size of the constant weight variables memory area.</div><div class="line">  uint64_t constantWeightVarsMemSize;</div><div class="line">  // Size of the mutable weight variables memory area.</div><div class="line">  uint64_t mutableWeightVarsMemSize;</div><div class="line">  // Size of the activations memory area.</div><div class="line">  uint64_t activationsMemSize;</div><div class="line">  // Alignment to be used for weights and activations.</div><div class="line">  uint64_t alignment;</div><div class="line">  // Number of symbols in the symbol table.</div><div class="line">  uint64_t numSymbols;</div><div class="line">  // Symbol table.</div><div class="line">  const SymbolTableEntry *symbolTable;</div><div class="line">};</div></div><!-- fragment --><p> This configuration is supposed to be used by the client code to allocate the required amounts of memory for each of the memory areas, before invoking the <code>&lt;network_name&gt;</code> function to run the network.</p>
<p>Clients also use <code>BundleConfig</code> to perform the symbol table lookups when they need to find information about an input or output variable. The SymbolTableEntry always has the following structure: </p><div class="fragment"><div class="line">{c++}</div><div class="line">struct SymbolTableEntry {</div><div class="line">  // Name of a variable.</div><div class="line">  const char *name;</div><div class="line">  // Offset of the variable inside the memory area.</div><div class="line">  uint64_t offset;</div><div class="line">  // The number of elements inside this variable.</div><div class="line">  uint64_t size;</div><div class="line">  // The kind of the variable. 1 if it is a mutable variable, 0 otherwise.</div><div class="line">  char kind;</div><div class="line">};</div></div><!-- fragment --><p>Offsets of constants are offsets inside the memory area for constant weights. Offsets of mutable variables are offsets inside the memory area for mutable weights.</p>
<h2>How to use the bundle</h2>
<p>This section describes the use of the CPU bundle. Other targets may have different interfaces.</p>
<p>To integrate the artifacts generated by the image-classifier into your project, you generally need to do the following:</p><ul>
<li>You need to link with the generated object file <code>&lt;network_name&gt;.o</code>.</li>
<li>You need to allocate the memory for constant weights variables, mutable weights variables (i.e. inputs and outputs) and activations based on the memory area sizes provided by <code>&lt;network_name&gt;_config</code>.</li>
<li>You need to load the content of the auto-generated <code>network_model_name.weights</code> file into the constant weights variables memory area.</li>
<li>And need to initialize the mutable weights area with inputs (e.g. image data)</li>
<li>And finally, you need to invoke the <code>&lt;network_name&gt;</code> function with 3 parameters that are base addresses of the memory areas for constant weights variables, mutable weights variables, and activations.</li>
<li>After <code>&lt;network_name&gt;</code> has returned, you can find the results of the mutable weights variables area.</li>
</ul>
<h2>A step-by-step example of the Resnet50 network model</h2>
<p>There are concrete examples of integrating a network model with a project located in the <code>examples/bundles/</code> directory in the Glow repository. You can enable the compilation of these bundles by invoking <code>cmake</code> with <code>-DGLOW_WITH_BUNDLES=ON -DGLOW_WITH_CPU=ON</code>.</p>
<h3>Floating point network</h3>
<p>To build and run the example, you just need to execute:</p><ul>
<li><code>cmake -G ninja &lt;other cmake flags&gt; -DGLOW_WITH_BUNDLES=ON -DGLOW_WITH_CPU=ON</code></li>
<li><code>ninja RunResNet50Bundle</code></li>
</ul>
<p>The CMakeLists.txt provides the following targets:</p><ul>
<li><code>ResNet50BundleNetFiles</code>: it downloads the Resnet50 network model in the Caffe2 format.</li>
<li><code>ResNet50BundleNet</code>: it generates the bundle files using the Glow image-classifier as described above. The concrete command line looks like this: <code>image-classifier tests/images/imagenet/cat_285.png -image-mode=0to1 -m=resnet50 -model-input-name=gpu_0/data -backend=CPU -emit-bundle &lt;build_dir&gt;</code> It reads the network model from <code>resnet50</code> and generates the <code>resnet50.o</code> and <code>resnet50.weights</code> files into the <code>build_dir</code> directory.</li>
<li><code>ResNet50BundleMain</code>: it compiles the <code>main.cpp</code> file, which is the main file of the project. This source file gives a good idea about how to interface with an auto-generated bundle. It contains the code for interfacing with the auto-generated bundle.<ul>
<li>It allocated the memory areas based on their memory sizes provided in <code>resnet50_config</code>.</li>
<li>Then it loads the weights from the auto-generated <code>resnet50.weights</code> file.</li>
<li>It loads the input image, pre-processes it and puts it into the mutable weight variables memory area.</li>
<li>Once everything is setup, it invokes the compiled network model by calling the <code>resnet50</code> function from the <code>resnet50.o</code> object file.</li>
</ul>
</li>
<li><code>ResNet50Bundle</code>: it links the user-defined <code>main.o</code> and auto-generated <code>resnet50.o</code> into a standalone executable file called <code>resnet50</code> <h3>Quantized network</h3>
</li>
</ul>
<p>All of the aforementioned targets have quantized versions in CMakeLists.txt named <code>QuantizedResNet50BundleNet</code>, <code>QuantizedResNet50Bundle</code>.</p>
<p>This run performs almost the same steps as non-quantized Resnet50 version except it emits bundle based on the quantization profile: <code>image-classifier tests/images/imagenet/cat_285.png -image-mode=0to1 -m=resnet50 -model-input-name=gpu_0/data -load-profile=profile.yml -backend=CPU -emit-bundle build</code></p>
<p>The <code>profile.yml</code> itself is captured at a prior step by executing image-classifier with the <code>dump-profile</code> option: <code>image-classifier tests/images/imagenet/*.png -image-mode=0to1 -m=resnet50 -model-input-name=gpu_0/data -dump-profile=profile.yml</code>.</p>
<p>See the <a href="../examples/bundles/resnet50/CMakeLists.txt">CMakeLists.txt</a> for details. </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
